logging_steps: 10
# log_level_replica: info

inf_free: true
model_name_or_path: opensearch-project/opensearch-neural-sparse-encoding-doc-v2-mini
tokenizer_name: opensearch-project/opensearch-neural-sparse-encoding-doc-v2-mini
idf_path: idf.json

max_seq_length: 512
train_file: data/scifact_train
data_type: posnegs
loss_types: [kldiv]
sample_num_one_query: 2
use_in_batch_negatives: true
flops_d_lambda: 0.002
flops_d_T: 200
ranking_loss_weight: 1
kd_ensemble_teacher_kwargs:
  types: ["dense", "sparse"]
  model_ids: ["Alibaba-NLP/gte-large-en-v1.5","opensearch-project/opensearch-neural-sparse-encoding-v1"]
  teacher_tokenizer_ids: ["Alibaba-NLP/gte-large-en-v1.5","opensearch-project/opensearch-neural-sparse-encoding-v1"]
  score_scale: 30

output_dir: output/test
per_device_eval_batch_size: 50
per_device_train_batch_size: 12

log_level: info
max_steps: 2000
fp16: true
learning_rate: 0.00002
weight_decay: 0.01
lr_scheduler_type: linear
warmup_steps: 200
save_strategy: steps
save_steps: 500
dataloader_drop_last: true
max_grad_norm: null